# üîÑ Desacoplamiento de Actualizaciones SQLite

## üìã Problema

**Situaci√≥n actual:**
- Datos de Banxico cambian **diariamente** (UDI, tipo de cambio, TIIE, CETES, inflaci√≥n)
- GitHub Actions actualiza JSONs diariamente
- Los JSONs est√°n **empaquetados dentro de la librer√≠a**
- ‚ùå **Cada actualizaci√≥n requiere un nuevo release** de catalogmx

**¬øPor qu√© es inviable?**
- Releases diarios contaminan versionado sem√°ntico
- Requiere changelog, git tags, CI/CD completo
- Usuarios deben `pip install --upgrade` diariamente
- PyPI, npm, pub.dev se saturan de versiones innecesarias

## üéØ Soluci√≥n Propuesta

### Arquitectura de Datos en Capas

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Datos EST√ÅTICOS (empaquetados)         ‚îÇ
‚îÇ  - Cat√°logos SAT (cambian 1-2 veces/a√±o)‚îÇ
‚îÇ  - C√≥digos postales SEPOMEX             ‚îÇ
‚îÇ  - Municipios/Estados INEGI             ‚îÇ
‚îÇ  - Placas, UMA, etc.                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Datos DIN√ÅMICOS (SQLite remoto)        ‚îÇ
‚îÇ  - UDIs Banxico (diario)                ‚îÇ
‚îÇ  - Tipo de cambio (diario)              ‚îÇ
‚îÇ  - TIIE, CETES (diario/semanal)         ‚îÇ
‚îÇ  - Inflaci√≥n (mensual)                  ‚îÇ
‚îÇ  - Salarios m√≠nimos (mensual)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Mecanismo de Actualizaci√≥n

**1. GitHub Releases como CDN de Datos**
```
Workflow diario:
‚îú‚îÄ‚îÄ Fetch datos de Banxico API
‚îú‚îÄ‚îÄ Actualizar mexico.sqlite3
‚îî‚îÄ‚îÄ Publicar en GitHub Releases (latest)
    ‚îî‚îÄ‚îÄ Tag: data-YYYY-MM-DD
```

**2. Auto-actualizaci√≥n en la Librer√≠a**
```python
from catalogmx.data import DataUpdater

# Autom√°tico (recomendado)
updater = DataUpdater()
updater.auto_update(max_age_hours=24)

# Manual
updater.download_latest()
updater.get_version()  # "2025-12-04"
```

**3. Cach√© Local + Fallback**
```
~/.catalogmx/
‚îú‚îÄ‚îÄ mexico.sqlite3          # √öltima versi√≥n descargada
‚îú‚îÄ‚îÄ version.json            # Metadata de versi√≥n
‚îî‚îÄ‚îÄ embedded/               # Fallback empaquetado
    ‚îî‚îÄ‚îÄ mexico.sqlite3
```

**Flujo de carga:**
1. ¬øExiste cach√© local? ‚Üí Verificar edad
2. ¬øEdad > 24 horas? ‚Üí Intentar actualizar
3. ¬øFall√≥ descarga? ‚Üí Usar cach√© local
4. ¬øNo hay cach√©? ‚Üí Usar datos empaquetados

## üèóÔ∏è Implementaci√≥n

### Fase 1: Infraestructura de Datos

**1.1. Crear `mexico_dynamic.sqlite3`**
```sql
-- Tablas para datos din√°micos de Banxico
CREATE TABLE udis (
    fecha TEXT PRIMARY KEY,
    valor REAL NOT NULL,
    a√±o INTEGER,
    mes INTEGER,
    tipo TEXT,  -- 'diario', 'mensual', 'anual'
    updated_at TEXT
);

CREATE TABLE tipo_cambio (
    fecha TEXT PRIMARY KEY,
    tipo_cambio REAL NOT NULL,
    a√±o INTEGER,
    fuente TEXT,  -- 'FIX', 'liquidacion', 'historico'
    updated_at TEXT
);

CREATE TABLE tiie (
    fecha TEXT,
    plazo INTEGER,  -- 28, 91, 182
    tasa REAL,
    updated_at TEXT,
    PRIMARY KEY (fecha, plazo)
);

CREATE TABLE cetes (
    fecha TEXT,
    plazo INTEGER,  -- 28, 91, 182, 364
    tasa REAL,
    updated_at TEXT,
    PRIMARY KEY (fecha, plazo)
);

CREATE TABLE inflacion (
    fecha TEXT PRIMARY KEY,
    inflacion_mensual REAL,
    inflacion_anual REAL,
    inpc REAL,
    updated_at TEXT
);

-- Metadata de versi√≥n
CREATE TABLE _metadata (
    key TEXT PRIMARY KEY,
    value TEXT,
    updated_at TEXT
);

INSERT INTO _metadata (key, value, updated_at) VALUES
('version', '2025-12-04', datetime('now')),
('source', 'banxico', datetime('now')),
('auto_update', 'true', datetime('now'));
```

**1.2. Script de Conversi√≥n JSON ‚Üí SQLite**
```python
# packages/shared-data/scripts/json_to_sqlite.py
import json
import sqlite3
from pathlib import Path

def migrate_banxico_to_sqlite():
    """Migrar todos los JSONs de Banxico a SQLite"""
    db = sqlite3.connect("mexico_dynamic.sqlite3")

    # UDIs
    with open("banxico/udis.json") as f:
        udis = json.load(f)
        db.executemany(
            "INSERT OR REPLACE INTO udis VALUES (?, ?, ?, ?, ?, datetime('now'))",
            [(r["fecha"], r["valor"], r["a√±o"], r["mes"], r["tipo"]) for r in udis]
        )

    # Tipo de cambio
    # TIIE, CETES, etc...

    db.commit()
    db.close()
```

### Fase 2: M√≥dulo de Actualizaci√≥n

**2.1. `catalogmx/data/updater.py`**
```python
"""
Data Updater - Descarga autom√°tica de datos din√°micos desde GitHub Releases
"""
import json
import sqlite3
from pathlib import Path
from datetime import datetime, timedelta
import urllib.request
import shutil

GITHUB_RELEASE_URL = "https://github.com/openbancor/catalogmx/releases/download/latest/mexico_dynamic.sqlite3"
CACHE_DIR = Path.home() / ".catalogmx"
CACHE_DB = CACHE_DIR / "mexico.sqlite3"
VERSION_FILE = CACHE_DIR / "version.json"
EMBEDDED_DB = Path(__file__).parent.parent / "data" / "mexico_embedded.sqlite3"

class DataUpdater:
    """Maneja la actualizaci√≥n autom√°tica de datos din√°micos"""

    def __init__(self):
        CACHE_DIR.mkdir(exist_ok=True)

    def get_local_version(self) -> str | None:
        """Obtener versi√≥n de datos locales"""
        if not VERSION_FILE.exists():
            return None
        with open(VERSION_FILE) as f:
            return json.load(f).get("version")

    def get_local_age_hours(self) -> float | None:
        """Obtener edad de datos locales en horas"""
        if not VERSION_FILE.exists():
            return None
        with open(VERSION_FILE) as f:
            updated = datetime.fromisoformat(json.load(f)["updated_at"])
            return (datetime.now() - updated).total_seconds() / 3600

    def download_latest(self, force: bool = False) -> bool:
        """Descargar √∫ltima versi√≥n de datos desde GitHub Releases"""
        try:
            print(f"üì• Descargando datos desde {GITHUB_RELEASE_URL}...")

            # Descargar a temporal
            temp_db = CACHE_DIR / "mexico.sqlite3.tmp"
            urllib.request.urlretrieve(GITHUB_RELEASE_URL, temp_db)

            # Verificar integridad
            db = sqlite3.connect(temp_db)
            version = db.execute("SELECT value FROM _metadata WHERE key = 'version'").fetchone()[0]
            db.close()

            # Mover a cach√©
            shutil.move(temp_db, CACHE_DB)

            # Guardar metadata
            with open(VERSION_FILE, "w") as f:
                json.dump({
                    "version": version,
                    "updated_at": datetime.now().isoformat(),
                    "source": "github_releases"
                }, f)

            print(f"‚úÖ Datos actualizados a versi√≥n {version}")
            return True

        except Exception as e:
            print(f"‚ùå Error descargando datos: {e}")
            return False

    def auto_update(self, max_age_hours: int = 24) -> Path:
        """
        Auto-actualizaci√≥n inteligente con fallback

        :param max_age_hours: Edad m√°xima antes de actualizar (default 24h)
        :return: Path a la base de datos a usar
        """
        age = self.get_local_age_hours()

        # Si no existe cach√© o es muy viejo, intentar actualizar
        if age is None or age > max_age_hours:
            if self.download_latest():
                return CACHE_DB

        # Si hay cach√© local v√°lido, usar
        if CACHE_DB.exists():
            return CACHE_DB

        # Fallback: datos empaquetados
        print("‚ö†Ô∏è  Usando datos empaquetados (puede estar desactualizado)")
        return EMBEDDED_DB

    def get_database_path(self, auto_update: bool = True) -> Path:
        """Obtener path a la base de datos (con o sin auto-update)"""
        if auto_update:
            return self.auto_update()

        if CACHE_DB.exists():
            return CACHE_DB

        return EMBEDDED_DB
```

**2.2. Migrar Cat√°logos a Usar DataUpdater**
```python
# catalogmx/catalogs/banxico/udis.py (NUEVO)
import sqlite3
from catalogmx.data.updater import DataUpdater

class UDICatalog:
    _db_path: Path | None = None

    @classmethod
    def _get_db(cls) -> sqlite3.Connection:
        """Obtener conexi√≥n a base de datos"""
        if cls._db_path is None:
            updater = DataUpdater()
            cls._db_path = updater.auto_update(max_age_hours=24)

        return sqlite3.connect(cls._db_path)

    @classmethod
    def get_por_fecha(cls, fecha: str) -> dict | None:
        """Obtener UDI por fecha"""
        db = cls._get_db()
        cursor = db.execute(
            "SELECT fecha, valor, a√±o, mes, tipo FROM udis WHERE fecha = ?",
            (fecha,)
        )
        row = cursor.fetchone()
        db.close()

        if not row:
            return None

        return {
            "fecha": row[0],
            "valor": row[1],
            "a√±o": row[2],
            "mes": row[3],
            "tipo": row[4]
        }

    # ... resto de m√©todos usando SQL queries
```

### Fase 3: Workflow de GitHub Actions

**3.1. `.github/workflows/update-dynamic-data.yml`**
```yaml
name: Update Dynamic Data (Daily)

on:
  schedule:
    - cron: '0 10 * * *'  # 4 AM M√©xico (10 UTC)
  workflow_dispatch:

jobs:
  update-data:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Fetch latest data from Banxico
        env:
          BANXICO_TOKEN: ${{ secrets.BANXICO_TOKEN }}
        run: |
          cd packages/shared-data
          python scripts/fetch_all_banxico.py

      - name: Build SQLite from JSONs
        run: |
          cd packages/shared-data
          python scripts/json_to_sqlite.py

      - name: Create Release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          VERSION=$(date +%Y-%m-%d)
          TAG="data-${VERSION}"

          gh release create "${TAG}" \
            packages/shared-data/mexico_dynamic.sqlite3 \
            --title "Data Update ${VERSION}" \
            --notes "Daily data update from Banxico (UDI, tipo cambio, TIIE, CETES, inflaci√≥n)"

          # Mover tag 'latest' a esta release
          gh release delete latest --yes || true
          gh release create latest \
            packages/shared-data/mexico_dynamic.sqlite3 \
            --title "Latest Data" \
            --notes "Always points to most recent data"
```

## üìä Comparaci√≥n: Antes vs Despu√©s

### Antes (Actual)
```
‚ùå Actualizaci√≥n de datos
‚îú‚îÄ‚îÄ 1. GitHub Action actualiza JSON
‚îú‚îÄ‚îÄ 2. Commit a main
‚îú‚îÄ‚îÄ 3. Crear release v1.2.301, v1.2.302, ...
‚îú‚îÄ‚îÄ 4. Publicar en PyPI, npm, pub.dev
‚îî‚îÄ‚îÄ 5. Usuario: pip install --upgrade catalogmx

Frecuencia: Diaria ‚Üí 365 releases/a√±o ü§Ø
```

### Despu√©s (Propuesto)
```
‚úÖ Actualizaci√≥n de datos
‚îú‚îÄ‚îÄ 1. GitHub Action actualiza SQLite
‚îî‚îÄ‚îÄ 2. Publica en GitHub Releases (data-YYYY-MM-DD)

Usuario:
‚îú‚îÄ‚îÄ Autom√°tico: DataUpdater descarga si >24h
‚îî‚îÄ‚îÄ Manual: catalogmx.data.update()

Frecuencia de releases de C√ìDIGO: 1-2 veces/mes
Frecuencia de datos: Diaria (sin tocar c√≥digo)
```

## üöÄ Migraci√≥n

### Para Usuarios

**Antes:**
```python
from catalogmx.catalogs.banxico import get_udi_actual

udi = get_udi_actual()  # Usa datos empaquetados (puede estar viejo)
```

**Despu√©s:**
```python
from catalogmx.catalogs.banxico import get_udi_actual
from catalogmx.data import DataUpdater

# Opci√≥n 1: Autom√°tico (recomendado)
udi = get_udi_actual()  # Auto-descarga si >24h

# Opci√≥n 2: Forzar actualizaci√≥n
updater = DataUpdater()
updater.download_latest(force=True)
udi = get_udi_actual()

# Opci√≥n 3: Verificar versi√≥n
print(updater.get_local_version())  # "2025-12-04"
print(f"Edad: {updater.get_local_age_hours():.1f} horas")
```

### Retrocompatibilidad

‚úÖ **100% compatible** con c√≥digo existente
- Misma API p√∫blica
- Mismo comportamiento
- Solo cambia el backend de datos

## üéØ Beneficios

### Para Desarrolladores
- ‚úÖ Releases solo cuando cambia **c√≥digo**
- ‚úÖ Versionado sem√°ntico real (1.2.3 ‚Üí 1.3.0)
- ‚úÖ Menos PRs autom√°ticos

### Para Usuarios
- ‚úÖ Datos **siempre actualizados** (sin reinstalar)
- ‚úÖ Funciona offline (fallback a cach√©)
- ‚úÖ Sin breaking changes

### Para CI/CD
- ‚úÖ GitHub Releases gratuito (100 GB)
- ‚úÖ CDN global de GitHub
- ‚úÖ Versionado de datos independiente

## üìù Plan de Implementaci√≥n

### Sprint 1: Base de Datos (1-2 d√≠as)
- [ ] Crear `mexico_dynamic.sqlite3` con schema
- [ ] Script `json_to_sqlite.py`
- [ ] Migrar UDIs, tipo_cambio, TIIE, CETES
- [ ] Tests de integridad

### Sprint 2: DataUpdater (2-3 d√≠as)
- [ ] Implementar `catalogmx.data.updater`
- [ ] Cach√© local + fallback
- [ ] Tests de descarga y fallback
- [ ] CLI: `catalogmx data update`

### Sprint 3: Migraci√≥n de Cat√°logos (2 d√≠as)
- [ ] Migrar `UDICatalog` a SQLite
- [ ] Migrar `TipoCambioUSDCatalog` a SQLite
- [ ] Migrar otros cat√°logos Banxico
- [ ] Tests end-to-end

### Sprint 4: Workflow (1 d√≠a)
- [ ] GitHub Actions workflow
- [ ] Publicar primera release de datos
- [ ] Documentaci√≥n de uso

### Sprint 5: Testing & Docs (1 d√≠a)
- [ ] Tests de integraci√≥n
- [ ] Actualizar README.md
- [ ] Gu√≠a de migraci√≥n

**Total: ~1 semana** de desarrollo

## üîß Configuraci√≥n

### Variables de Entorno
```bash
# Deshabilitar auto-actualizaci√≥n (√∫til para CI/CD)
export CATALOGMX_AUTO_UPDATE=false

# Cambiar directorio de cach√©
export CATALOGMX_CACHE_DIR=/custom/path

# URL personalizada (self-hosted)
export CATALOGMX_DATA_URL=https://mycdn.com/mexico.sqlite3
```

### Configuraci√≥n Program√°tica
```python
from catalogmx.data import config

config.AUTO_UPDATE = False
config.CACHE_DIR = Path("/custom/path")
config.MAX_AGE_HOURS = 12  # Actualizar cada 12h
```

## üìö Referencias

- [SQLite as CDN](https://til.simonwillison.net/sqlite/one-line-csv-operations)
- [GitHub Releases API](https://docs.github.com/en/rest/releases)
- [Data Versioning Best Practices](https://dvc.org/doc/start/data-versioning)

---

**Autor:** Claude AI + Luis Fernando Barrera
**Fecha:** 2025-12-04
**Estado:** ‚úÖ Propuesta Aprobada ‚Üí En Implementaci√≥n
